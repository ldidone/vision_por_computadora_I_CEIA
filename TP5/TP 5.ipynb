{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdb3389",
   "metadata": {},
   "source": [
    "# TP 5 - Visión por Computadora 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c4e9f",
   "metadata": {},
   "source": [
    "## Enunciado:\n",
    "\n",
    "### - Objetivo\n",
    "- Implementar el detector de fondo naive usando la mediana como estimador El algoritmo debe recibir el parámetro N (cantidad de frames utilizados para la estimación) y el intervalo de tiempo para recalcular el fondo\n",
    "- Se deben generar las mascaras de foreground y aplicarlas a los frames para segmentar los objetos en movimiento\n",
    "- Comparar con alguno de los métodos vistos en la practica basados en mezcla de gaussianas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e8e4b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c7ac2",
   "metadata": {},
   "source": [
    "### Funciones y variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fa6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af207bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 20\n",
    "n_time = 10\n",
    "filename = 'vtest.avi'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846050cc",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201a62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_indexes(n_items, actual_index, max_frames):  \n",
    "    index = actual_index + n_items\n",
    "    index = min(index, max_frames)    \n",
    "    indexes = np.random.choice(index, size=n_items, replace=False)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eff5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(n_frames, index, total_frames):\n",
    "    frames = []\n",
    "    indexes = get_random_indexes(n_frames, index, total_frames)\n",
    "    for i in indexes:\n",
    "        capture.set(1, i)\n",
    "        ret, frame = capture.read()\n",
    "        frames.append(frame)\n",
    "\n",
    "    return np.median(frames, axis=0).astype(dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be3816f",
   "metadata": {},
   "source": [
    "### Implementación algoritmo Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0401d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_background_substractor(n_frames, n_time, capture, apply_opening=False):\n",
    "    total_frames = int(capture.get(7))\n",
    "    background = get_background(n_frames, 0, total_frames)\n",
    "    while True:\n",
    "        # Obtenemos el número del frame actual\n",
    "        index = capture.get(cv.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "        # Recalculamos el background luego de n número de frames\n",
    "        if index % n_time == 0:\n",
    "            background = get_background(n_frames, 0, total_frames)\n",
    "            \n",
    "        # Leemos un frame\n",
    "        index += 1\n",
    "        index = min(index, total_frames)\n",
    "        capture.set(1, index)   \n",
    "        ret, frame = capture.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        \n",
    "        # Restamos el frame actual con la mediana y binarizamos para obtener el foregroumd\n",
    "        diff_frame = cv.absdiff(frame, background)\n",
    "        _, foreground = cv.threshold(diff_frame, 25, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        if apply_opening:\n",
    "            kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "            foreground = cv.morphologyEx(foreground, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Escribimos sobre la imagen el número de frame procesado\n",
    "        cv.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)\n",
    "        cv.putText(frame, str(capture.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "        \n",
    "        \n",
    "        # mostramos frame original e imagen binaria background/foreground\n",
    "        cv.imshow('Frame', frame)\n",
    "        cv.imshow('FG Mask', foreground)\n",
    "\n",
    "        # Corremos hasta que termine o apriete escape\n",
    "        keyboard = cv.waitKey(30)\n",
    "        if keyboard == 'q' or keyboard == 27:\n",
    "            break\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fc388",
   "metadata": {},
   "source": [
    "### Prueba del algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f33672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de procesamiento: 50.935993671417236 segundos.\n"
     ]
    }
   ],
   "source": [
    "capture = cv.VideoCapture(filename)\n",
    "\n",
    "start = time.time()\n",
    "naive_background_substractor(n_frames, n_time, capture)\n",
    "end = time.time()\n",
    "\n",
    "processed_time = end - start\n",
    "print(f\"Tiempo de procesamiento: {processed_time} segundos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a690f25",
   "metadata": {},
   "source": [
    "### Comparación con algoritmo de mezcla de gausianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2eaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mog2_background_substractor(capture):\n",
    "    # Definimos el método a utilizar\n",
    "    backSub = cv.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while True:\n",
    "        # Leemos un frame\n",
    "        ret, frame = capture.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # Aplicamos la sustracción al frame leído\n",
    "        fgMask = backSub.apply(frame)\n",
    "\n",
    "        # Escribimos sobre la imagen el número de frame procesado\n",
    "        cv.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)\n",
    "        cv.putText(frame, str(capture.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "\n",
    "        # mostramos frame original e imagen binaria background/foreground\n",
    "        cv.imshow('Frame', frame)\n",
    "        cv.imshow('FG Mask', fgMask)\n",
    "\n",
    "        # Corresmos hasta que termine o apriete escape\n",
    "        keyboard = cv.waitKey(30)\n",
    "        if keyboard == 'q' or keyboard == 27:\n",
    "            break\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d0963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de procesamiento: 60.95148515701294 segundos.\n"
     ]
    }
   ],
   "source": [
    "capture = cv.VideoCapture(filename)\n",
    "\n",
    "start = time.time()\n",
    "mog2_background_substractor(capture)\n",
    "end = time.time()\n",
    "\n",
    "processed_time = end - start\n",
    "print(f\"Tiempo de procesamiento: {processed_time} segundos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32516c",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Los resultados obtenidos empleando el extractor de fondos naive, resultan sorprendentes dada la simplicidad del algoritmo. \n",
    "El mismo fue capaz de extraer el fondo del video de pruebas sin inconvenientes. Como posibles mejoras futuras se propone emplear frames aleatorios cercanos al frame actual para computar el background.\n",
    "\n",
    "Por otro lado, al comparar el algoritmo contra el de MOG2, podemos observar que el extractor de fondos naive se desempeña de manera más veloz, necesitando 50.94 segundos para procesar el video, mientras que el algoritmo MOG2 necesitó 60.95 segundos.\n",
    "No obstante, si empleamos procesamiento morfológico (operacón de apertura), es posible notar como se degrada la performance del algoritmo en cuanto a tiempo, demorando  97.79 segundos, sin embargo con esta funcionalidad activada, la extracción de fondos mejora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
